# -*- coding: utf-8 -*-
"""deep_dream.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BXwGWfLaUvZYWHyYdire26VsLMRgXRKX
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import PIL.Image
import numpy as np
from scipy.ndimage.filters import gaussian_filter

import inception5h

inception5h.maybe_download()

model=inception5h.Inception5h()

#number of layers we will use for deep dream
len(model.layer_tensors)

#loading image
def load_image(filename):
  
  image =PIL.Image.open(filename)
  
  return np.float32(image)

#saving image
def save_image(image,filename):
  image=np.clip(image,0.0,255.0)
  image=image.astype(np.uint8)
  
  with open(filename,'wb') as file:
    PIL.Image.fromarray(image).save(file,'jpeg')

def plot_image(image):
  if False:
    # Convert the pixel-values to the range between 0.0 and 1.0
    image = np.clip(image/255.0, 0.0, 1.0)
        
    # Plot using matplotlib.
    plt.imshow(image, interpolation='lanczos')
    plt.show()
    
  else:
    #plot using pil
    image=np.clip(image,0.0,255.0)
  
    image=image.astype(np.uint8)
    
    display(PIL.Image.fromarray(image))

#normalizing image used for plotting gradient
def normalize_image(x):
  #take max and min value of pixels in input
  x_min=x.min()
  x_max=x.max()
  
  #normalize in range 0-1
  x_normalize=(x-x_min)/(x_max-x_min)
  
  return x_normalize

def plot_gradient(gradient):
  #normalize the gradient in range 0-1
  
  gradient_normalized=normalize_image(gradient)
  
  plt.imshow(gradient_normalized,interpolation='bilinear')
  plt.show()

def resize_image(image,size=None,factor=None):
  if factor is not None:
    #scale heigth and width
    size=np.array(image.shape[0:2])* factor
    
    #as size is float-point but pil requires integers
    size=size.astype(int)
  
  else:
    size=size[0:2]
    
  #heigth and width is reversed in numpy vs pil
  size=tuple(reversed(size))
  
  img=np.clip(image,0.0,255.0)
  
  img=img.astype(np.uint8)
  img=PIL.Image.fromarray(img)
  
  
  #resize the image
  img_resized=img.resize(size,PIL.Image.LANCZOS)
  
  #convert 8-bit pixel back to float-point
  
  img_resized=np.float32(img_resized)
  
  return img_resized

import math
import random
def get_tile_size(num_pixels,tile_size=400):
  
  num_tiles=int(round(num_pixels/tile_size))
  
  num_tiles=max(1,num_tiles)
  
  actual_tile_size = math.ceil(num_pixels/num_tiles)
  
  return actual_tile_size

def tiled_gradient(gradient,image,tile_size=400):
  
  grad= np.zeros_like(image)
  
  x_max,y_max,_=image.shape
  
  #x-axis tile size
  x_tile_size=get_tile_size(num_pixels=x_max,tile_size=tile_size)
  
  x_tile_size4=x_tile_size//4
  
  #y-axis tile size
  y_tile_size=get_tile_size(num_pixels=y_max,tile_size=tile_size)
  
  y_tile_size4=y_tile_size//4
  
  #random start-position for the tiles on the x-axis b/w -3/4 and -1/4 of tile size
  x_start=random.randint(-3*x_tile_size4, -x_tile_size4)
  
  while(x_start < x_max):
    x_end=x_start +x_tile_size
    
    x_start_lim=max(x_start,0)
    x_end_lim=min(x_end,x_max)
    
    y_start=random.randint(-3*y_tile_size4,-y_tile_size4)
    
    while(y_start<y_max):
      y_end=y_start+y_tile_size
      
      y_start_lim=max(y_start,0)
      y_end_lim=min(y_end,y_max)
      
      img_tile=image[x_start_lim:x_end_lim,y_start_lim:y_end_lim,:]
      
      feed_dict=model.create_feed_dict(image=img_tile)
      
      #calculate gradient value
      
      g=session.run(gradient,feed_dict=feed_dict)
      
      #normalize gradient for tile
      
      g/=(np.std(g) + 1e-8)
      
      #storing gradient of tile
      
      grad[x_start_lim:x_end_lim,y_start_lim:y_end_lim,:]=g
      
      #next y-start position
      y_start=y_end
    
    #next x-start position  
    x_start=x_end
     
  return grad

#optimization for deep dream algorithm(i.e,calculating gradient of particular inception model with respect to input image and adding it to input image 
#to increase the mean value of the layer tensor , it is repeated many times
#to get the features in the inception model layer)
#Using Gradient Ascent to optimize image

def optimize_image(layer_tensor,image,num_iterations=10,step_size=3.0,tile_size=400,show_gradient=False):
  img=image.copy()
  print("iamge before:")
  
  plot_image(img)
  
  print("processing_image",end="")
  
  gradient=model.get_gradient(layer_tensor)
  
  for i in range(num_iterations):
    grad=tiled_gradient(gradient=gradient,image=img,tile_size=tile_size)
    
    sigma=(i*4.0)/num_iterations+0.5
    
    grad_smooth1=gaussian_filter(grad,sigma=sigma)
    grad_smooth2=gaussian_filter(grad,sigma=sigma*2)
    grad_smooth3=gaussian_filter(grad,sigma=sigma*0.5)
    
    grad=(grad_smooth1+grad_smooth2+grad_smooth3)
    
    #Scale the step-size according to the gradient-values(not necessary bec tiled_gradient is already normalized)
    
    step_size_scaled=step_size/(np.std(grad)+1e-8)
    
    #adding gradient to image
    img=img+ grad*step_size_scaled
    
    if show_gradient:
      msg="gradient min:{0:>9.6f},max:{1:>9.6f},step_size:{2:>9.6f}".format(grad.min(),grad.max(),step_size_scaled)
      print(msg)
      
      plot_gradient(grad)
      
    else:
      print(".",end="")
      
    print("image_after:")
    plot_image(img)
    
    return img

def recursive_optimize(layer_tensor, image,
                       num_repeats=4, rescale_factor=0.7, blend=0.2,
                       num_iterations=10, step_size=3.0,
                       tile_size=400):
    """
    Recursively blur and downscale the input image.
    Each downscaled image is run through the optimize_image()
    function to amplify the patterns that the Inception model sees.

    Parameters:
    image: Input image used as the starting point.
    rescale_factor: Downscaling factor for the image.
    num_repeats: Number of times to downscale the image.
    blend: Factor for blending the original and processed images.

    Parameters passed to optimize_image():
    layer_tensor: Reference to a tensor that will be maximized.
    num_iterations: Number of optimization iterations to perform.
    step_size: Scale for each step of the gradient ascent.
    tile_size: Size of the tiles when calculating the gradient.
    """

    # Do a recursive step?
    if num_repeats>0:
        # Blur the input image to prevent artifacts when downscaling.
        # The blur amount is controlled by sigma. Note that the
        # colour-channel is not blurred as it would make the image gray.
        sigma = 0.5
        img_blur = gaussian_filter(image, sigma=(sigma, sigma, 0.0))

        # Downscale the image.
        img_downscaled = resize_image(image=img_blur,
                                      factor=rescale_factor)
            
        # Recursive call to this function.
        # Subtract one from num_repeats and use the downscaled image.
        img_result = recursive_optimize(layer_tensor=layer_tensor,
                                        image=img_downscaled,
                                        num_repeats=num_repeats-1,
                                        rescale_factor=rescale_factor,
                                        blend=blend,
                                        num_iterations=num_iterations,
                                        step_size=step_size,
                                        tile_size=tile_size)
        
        # Upscale the resulting image back to its original size.
        img_upscaled = resize_image(image=img_result, size=image.shape)

        # Blend the original and processed images.
        image = blend * image + (1.0 - blend) * img_upscaled

    print("Recursive level:", num_repeats)

    # Process the image using the DeepDream algorithm.
    img_result = optimize_image(layer_tensor=layer_tensor,
                                image=image,
                                num_iterations=num_iterations,
                                step_size=step_size,
                                tile_size=tile_size)
    
    return img_result

def recursive_optimize(layer_tensor,image,num_repeats=4,rescale_factor=0.7,blend=0.2,num_iterations=10,step_size=3,tile_size=400):
  #here image is downscaled in each recursion and for ampliying is send to function optimize image
  
  #base case
  if num_repeats>0:
    #blur image during downsampling , which is controlled by sigma
    sigma=0.5
    img_blur=gaussian_filter(image,sigma=(sigma,sigma,0.0))
    
    #downscaling image
    img_downscaled=resize_image(image=img_blur,factor=rescale_factor)
    
    #recursive calls
    img_result=recursive_optimize(layer_tensor=layer_tensor,image=img_downscaled,num_repeats=num_repeats-1,rescale_factor=rescale_factor,blend=blend,num_iterations=num_iterations,step_size=step_size,tile_size=tile_size)
    
    #upscaling image
    
    img_upscaled=resize_image(image=img_result,size=image.shape)
    
    image=blend*image+(1.0-blend)*img_upscaled
  print("recursive calls:",num_repeats)
    
  #processing image using deepdream algorithm
  img_result=optimize_image(layer_tensor=layer_tensor,image=image,num_iterations=num_iterations,step_size=step_size,tile_size=tile_size)
    
  return img_result

session=tf.InteractiveSession(graph=model.graph)

image=load_image(filename='WhatsApp Image 2019-03-18 at 3.07.12 PM.jpeg')
plot_image(image)

layer_tensor=model.layer_tensors[4]
layer_tensor

img_result = optimize_image(layer_tensor, image,num_iterations=10, step_size=6.0, tile_size=400,show_gradient=True)

layer_tensor = model.layer_tensors[6]
img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,num_iterations=10, step_size=3.0, rescale_factor=0.7,num_repeats=4, blend=0.2)

layer_tensor = model.layer_tensors[7][:,:,:,0:3]
img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,
                 num_iterations=10, step_size=3.0, rescale_factor=0.7,
                 num_repeats=4, blend=0.2)

layer_tensor = model.layer_tensors[11][:,:,:,0]
img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,
                 num_iterations=10, step_size=3.0, rescale_factor=0.7,
                 num_repeats=4, blend=0.2)

